{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Eland and low-level Elasticsearch clients for comparison\n",
    "import eland as ed\n",
    "from eland.conftest import *\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "\n",
    "# Import pandas and numpy for data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For pretty-printing\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the index we want to query\n",
    "index_name = 'twinttweets' \n",
    "\n",
    "# instantiating client connect to localhost by default\n",
    "es = Elasticsearch()\n",
    "\n",
    "# # defining the search statement to get all records in an index\n",
    "# search = Search(using=es, index=index_name).query(\"match_all\") \n",
    "\n",
    "# # retrieving the documents from the search\n",
    "# documents = [hit.to_dict() for hit in search.scan()] \n",
    "\n",
    "# # converting the list of hit dictionaries into a pandas dataframe:\n",
    "# df_stocks = pd.DataFrame.from_records(documents)\n",
    "# # visualizing the dataframe with the results:\n",
    "# df_stocks.head()['tweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data into Eland dataframe:\n",
    "ed_stocks = ed.read_es('localhost', index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert query for snap into a pandas dataframe \n",
    "data = ed.eland_to_pandas(ed_stocks[ed_stocks['tweet'].es_match(\"SNAP\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'$msft $sunw $tsla $fsly $wkhs $penn $spy $pfe $aal $dkng $hexo $novn $fsr $aapl $gme $acb $fb $sndl $snap $gaxy  $blnk $gevo $nio $vxrt $rkt $nkla $opti $xspa $srne  WE ALERTED $IBIO at $1.45 RAN TO $7 (370% GAIN!)   Daily Alerts  $15 ONE TIME FEE  BEAT THAT ðŸ‘‡ðŸ‘‡ ðŸš¨LINK IN BIOðŸš¨'"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "#grab a single index from that data frame \n",
    "tweet = data['tweet'][80]\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertModel: ['dropout_19', 'pre_classifier', 'classifier']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['dropout_545']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "label: NEGATIVE, with score: 0.9975\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline \n",
    "\n",
    "nlp = pipeline(\"sentiment-analysis\")\n",
    "result = nlp(tweet)[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9974581599235535}]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}